{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building_EfficientNet_model_using_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PotatoSpudowski/CactiNet/blob/master/Building_EfficientNet_model_using_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2-A6Viz1whd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim \n",
        "\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.utils.data as utils\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IQQHfMu6wW6",
        "colab_type": "text"
      },
      "source": [
        "###Defining Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_HwGVnC-vxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Swish activation function\n",
        "class Swish(nn.Module):\n",
        "    \"\"\"\n",
        "    Activation function designed to kick ReLU's @$$\n",
        "    \"\"\"\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckoeue1tFkzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv2D_with_same_padding(nn.Conv2d):\n",
        "    \"\"\"\n",
        "    Conv2d layer with padding implemented in a way such that size of \n",
        "    the input features and the output features remain same.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch, out_ch, kernel_size, stride=1, dilation=1, groups=1, bias=True, padding_mode=\"zeros\"):\n",
        "        super().__init__(in_ch, out_ch, kernel_size, stride, 0, dilation, groups, bias, padding_mode)\n",
        "\n",
        "    def get_odd_padding(self, in_ch, weight, stride, dilation):\n",
        "        filter_row =  (weight - 1) * dilation + 1\n",
        "        out_rows = (in_ch + stride - 1) // stride\n",
        "        padding = max(0, (out_rows - 1) * stride + filter_row - in_ch)\n",
        "        padding_val= max(0, (out_rows - 1) * stride + (weight - 1) * dilation + 1 - in_ch)\n",
        "        odd = (padding_val % 2 != 0)\n",
        "        return padding_val, odd\n",
        "\n",
        "    def forward(self, x):\n",
        "        padding_row, row_odd = self.get_odd_padding(x.shape[2], self.weight.shape[2], self.stride[0], self.dilation[0])\n",
        "        padding_collumn, collumn_odd = self.get_odd_padding(x.shape[3], self.weight.shape[3], self.stride[1], self.dilation[1])\n",
        "\n",
        "        if row_odd or collumn_odd:\n",
        "            x = F.pad(x, [0, int(collumn_odd), 0, int(row_odd)])\n",
        "        \n",
        "        return F.conv2d(x, self.weight, self.bias, self.stride,\n",
        "                        padding = (padding_row // 2, padding_collumn //2),\n",
        "                        dilation = self.dilation,\n",
        "                        groups=self.groups)\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "class SqueezeExcitationModule(nn.Module):\n",
        "    def __init__(self, in_ch, squeeze_ch):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_ch, squeeze_ch, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            Swish(),\n",
        "            nn.Conv2d(squeeze_ch, in_ch, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(self.se(x))\n",
        "\n",
        "class DropConnections(nn.Module):\n",
        "    \"\"\"\n",
        "    Rndomly disables individual weights\n",
        "    \"\"\"\n",
        "    def __init__(self, ratio):\n",
        "        super().__init__()\n",
        "        self.ratio = 1.0 - ratio\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.training:\n",
        "            return x\n",
        "\n",
        "        ran_tensor = self.ratio\n",
        "        ran_tens += torch.rand([x.shape[0], 1, 1, 1], dtype=torch.float, device=x.device)\n",
        "        ran_tensor.requires_grad_(False)\n",
        "        return x / self.ratio * ran_tensor.floor()\n",
        "\n",
        "def Conv_BatchNorm_Activation(in_ch, out_ch, kernel_size, stride=1, groups=1, bias=True, eps=1e-3, momentum=0.01):\n",
        "    return nn.Sequential(\n",
        "        Conv2D_with_same_padding(in_ch, out_ch, kernel_size, stride, groups=groups, bias=bias),\n",
        "        nn.BatchNorm2d(out_ch, eps, momentum),\n",
        "        Swish()\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6eqsdy30x16",
        "colab_type": "text"
      },
      "source": [
        "###Defining MBConv layer and MBConv Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzQwM_lPJM1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MBConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, expand, kernel_size, stride, skip, se_ratio, dc_ratio=0.2):\n",
        "        super().__init__()\n",
        "        mid = in_ch * expand\n",
        "        if expand != 0:\n",
        "            self.expand_conv = Conv_BatchNorm_Activation(in_ch, mid, kernel_size=1, bias = False)\n",
        "        else:\n",
        "            nn.Identity()\n",
        "\n",
        "        self.depth_wise_conv = Conv_BatchNorm_Activation(mid, mid, kernel_size=kernel_size, stride=stride, groups=mid, bias=False)\n",
        "\n",
        "        if se_ratio > 0:\n",
        "            self.se = SqueezeExcitationModule(mid, int(in_ch * se_ratio)) \n",
        "        else:\n",
        "            nn.Identity()\n",
        "\n",
        "        self.project_conv = nn.Sequential(\n",
        "            Conv2D_with_same_padding(mid, out_ch, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch, 1e-3, 0.01)\n",
        "        )\n",
        "\n",
        "        self.skip = skip and (stride == 1) and (in_ch == out_ch)\n",
        "\n",
        "        self.dropconnect = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        expand = self.expand_conv(x)\n",
        "        x1 = self.depth_wise_conv(expand)\n",
        "        x1 = self.se(x1)\n",
        "        x1 = self.project_conv(x1)\n",
        "        if self.skip:\n",
        "            x1 = self.dropconnect(x1)\n",
        "            x1 = x1 + x\n",
        "        return x1\n",
        "\n",
        "class MBBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, expand, kernel, stride, num_repeat, skip, se_ratio, drop_connect_ratio=0.2):\n",
        "        super().__init__()\n",
        "        layers = [\n",
        "            MBConv(in_ch, out_ch, expand, kernel, stride, skip, se_ratio, drop_connect_ratio)\n",
        "        ]\n",
        "\n",
        "        for i in range(1, num_repeat):\n",
        "            layers.append(MBConv(out_ch, out_ch, expand, kernel, 1, skip, se_ratio, drop_connect_ratio))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return  self.layers(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln44To9i1HSI",
        "colab_type": "text"
      },
      "source": [
        "##Building the CactiNet model\n",
        "Which is btw totally based on the EfficientNet-b0 model with a few additional MBBlock and change in channel sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2faiiii_pzZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CactiNet(nn.Module):\n",
        "    def __init__(self, width_coeff=1, depth_coeff=1, depth_div=8, min_depth=None, dropout_rate=0.2, drop_connect_rate=0.2, num_classes=1):\n",
        "        super().__init__()\n",
        "        min_depth = min_depth or depth_div\n",
        "\n",
        "        def renew_ch(x):\n",
        "            if not width_coeff:\n",
        "                return x\n",
        "\n",
        "            x *= width_coeff\n",
        "            new_x = max(min_depth, int(x + depth_div / 2) // depth_div * depth_div)\n",
        "            if new_x < 0.9 * x:\n",
        "                new_x += depth_div\n",
        "            return int(new_x)\n",
        "\n",
        "        def renew_repeat(x):\n",
        "            return int(math.ceil(x * depth_coeff))\n",
        "\n",
        "        self.stem = Conv_BatchNorm_Activation(3, renew_ch(32), kernel_size=3, stride=2, bias=False)\n",
        "\n",
        "        self.blocks = nn.Sequential(\n",
        "            MBBlock(renew_ch(32), renew_ch(18), 1, 3, 1, renew_repeat(1), True, 0.25, drop_connect_rate),\n",
        "            MBBlock(renew_ch(18), renew_ch(28), 6, 3, 2, renew_repeat(2), True, 0.25, drop_connect_rate),\n",
        "            MBBlock(renew_ch(28), renew_ch(46), 6, 5, 2, renew_repeat(2), True, 0.25, drop_connect_rate),\n",
        "            MBBlock(renew_ch(46), renew_ch(80), 6, 3, 2, renew_repeat(3), True, 0.25, drop_connect_rate),\n",
        "            MBBlock(renew_ch(80), renew_ch(122), 6, 5, 1, renew_repeat(3), True, 0.25, drop_connect_rate),\n",
        "            MBBlock(renew_ch(122), renew_ch(192), 6, 5, 2, renew_repeat(4), True, 0.25, drop_connect_rate),\n",
        "            MBBlock(renew_ch(192), renew_ch(320), 6, 3, 1, renew_repeat(1), True, 0.25, drop_connect_rate)\n",
        "        )\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            *Conv_BatchNorm_Activation(renew_ch(320), renew_ch(1280), kernel_size=1, bias=False),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Dropout2d(dropout_rate, True),\n",
        "            Flatten(),\n",
        "            nn.Linear(renew_ch(1280), num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        stem = self.stem(inputs)\n",
        "        x = self.blocks(stem)\n",
        "        head = self.head(x)\n",
        "        return head"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K1p1L48vgfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CactiNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7rdcnSbxI3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvZTcGtPxOcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "965c5b07-36bd-47b8-dded-de6ed737547e"
      },
      "source": [
        "summary(model, (3, 40, 40))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "Conv2D_with_same_padding-1           [-1, 32, 20, 20]             864\n",
            "       BatchNorm2d-2           [-1, 32, 20, 20]              64\n",
            "             Swish-3           [-1, 32, 20, 20]               0\n",
            "Conv2D_with_same_padding-4           [-1, 32, 20, 20]           1,024\n",
            "       BatchNorm2d-5           [-1, 32, 20, 20]              64\n",
            "             Swish-6           [-1, 32, 20, 20]               0\n",
            "Conv2D_with_same_padding-7           [-1, 32, 20, 20]             288\n",
            "       BatchNorm2d-8           [-1, 32, 20, 20]              64\n",
            "             Swish-9           [-1, 32, 20, 20]               0\n",
            "AdaptiveAvgPool2d-10             [-1, 32, 1, 1]               0\n",
            "           Conv2d-11              [-1, 8, 1, 1]             264\n",
            "            Swish-12              [-1, 8, 1, 1]               0\n",
            "           Conv2d-13             [-1, 32, 1, 1]             288\n",
            "SqueezeExcitationModule-14           [-1, 32, 20, 20]               0\n",
            "Conv2D_with_same_padding-15           [-1, 24, 20, 20]             768\n",
            "      BatchNorm2d-16           [-1, 24, 20, 20]              48\n",
            "           MBConv-17           [-1, 24, 20, 20]               0\n",
            "          MBBlock-18           [-1, 24, 20, 20]               0\n",
            "Conv2D_with_same_padding-19          [-1, 144, 20, 20]           3,456\n",
            "      BatchNorm2d-20          [-1, 144, 20, 20]             288\n",
            "            Swish-21          [-1, 144, 20, 20]               0\n",
            "Conv2D_with_same_padding-22          [-1, 144, 10, 10]           1,296\n",
            "      BatchNorm2d-23          [-1, 144, 10, 10]             288\n",
            "            Swish-24          [-1, 144, 10, 10]               0\n",
            "AdaptiveAvgPool2d-25            [-1, 144, 1, 1]               0\n",
            "           Conv2d-26              [-1, 6, 1, 1]             870\n",
            "            Swish-27              [-1, 6, 1, 1]               0\n",
            "           Conv2d-28            [-1, 144, 1, 1]           1,008\n",
            "SqueezeExcitationModule-29          [-1, 144, 10, 10]               0\n",
            "Conv2D_with_same_padding-30           [-1, 32, 10, 10]           4,608\n",
            "      BatchNorm2d-31           [-1, 32, 10, 10]              64\n",
            "           MBConv-32           [-1, 32, 10, 10]               0\n",
            "Conv2D_with_same_padding-33          [-1, 192, 10, 10]           6,144\n",
            "      BatchNorm2d-34          [-1, 192, 10, 10]             384\n",
            "            Swish-35          [-1, 192, 10, 10]               0\n",
            "Conv2D_with_same_padding-36          [-1, 192, 10, 10]           1,728\n",
            "      BatchNorm2d-37          [-1, 192, 10, 10]             384\n",
            "            Swish-38          [-1, 192, 10, 10]               0\n",
            "AdaptiveAvgPool2d-39            [-1, 192, 1, 1]               0\n",
            "           Conv2d-40              [-1, 8, 1, 1]           1,544\n",
            "            Swish-41              [-1, 8, 1, 1]               0\n",
            "           Conv2d-42            [-1, 192, 1, 1]           1,728\n",
            "SqueezeExcitationModule-43          [-1, 192, 10, 10]               0\n",
            "Conv2D_with_same_padding-44           [-1, 32, 10, 10]           6,144\n",
            "      BatchNorm2d-45           [-1, 32, 10, 10]              64\n",
            "         Identity-46           [-1, 32, 10, 10]               0\n",
            "           MBConv-47           [-1, 32, 10, 10]               0\n",
            "          MBBlock-48           [-1, 32, 10, 10]               0\n",
            "Conv2D_with_same_padding-49          [-1, 192, 10, 10]           6,144\n",
            "      BatchNorm2d-50          [-1, 192, 10, 10]             384\n",
            "            Swish-51          [-1, 192, 10, 10]               0\n",
            "Conv2D_with_same_padding-52            [-1, 192, 5, 5]           4,800\n",
            "      BatchNorm2d-53            [-1, 192, 5, 5]             384\n",
            "            Swish-54            [-1, 192, 5, 5]               0\n",
            "AdaptiveAvgPool2d-55            [-1, 192, 1, 1]               0\n",
            "           Conv2d-56              [-1, 8, 1, 1]           1,544\n",
            "            Swish-57              [-1, 8, 1, 1]               0\n",
            "           Conv2d-58            [-1, 192, 1, 1]           1,728\n",
            "SqueezeExcitationModule-59            [-1, 192, 5, 5]               0\n",
            "Conv2D_with_same_padding-60             [-1, 48, 5, 5]           9,216\n",
            "      BatchNorm2d-61             [-1, 48, 5, 5]              96\n",
            "           MBConv-62             [-1, 48, 5, 5]               0\n",
            "Conv2D_with_same_padding-63            [-1, 288, 5, 5]          13,824\n",
            "      BatchNorm2d-64            [-1, 288, 5, 5]             576\n",
            "            Swish-65            [-1, 288, 5, 5]               0\n",
            "Conv2D_with_same_padding-66            [-1, 288, 5, 5]           7,200\n",
            "      BatchNorm2d-67            [-1, 288, 5, 5]             576\n",
            "            Swish-68            [-1, 288, 5, 5]               0\n",
            "AdaptiveAvgPool2d-69            [-1, 288, 1, 1]               0\n",
            "           Conv2d-70             [-1, 12, 1, 1]           3,468\n",
            "            Swish-71             [-1, 12, 1, 1]               0\n",
            "           Conv2d-72            [-1, 288, 1, 1]           3,744\n",
            "SqueezeExcitationModule-73            [-1, 288, 5, 5]               0\n",
            "Conv2D_with_same_padding-74             [-1, 48, 5, 5]          13,824\n",
            "      BatchNorm2d-75             [-1, 48, 5, 5]              96\n",
            "         Identity-76             [-1, 48, 5, 5]               0\n",
            "           MBConv-77             [-1, 48, 5, 5]               0\n",
            "          MBBlock-78             [-1, 48, 5, 5]               0\n",
            "Conv2D_with_same_padding-79            [-1, 288, 5, 5]          13,824\n",
            "      BatchNorm2d-80            [-1, 288, 5, 5]             576\n",
            "            Swish-81            [-1, 288, 5, 5]               0\n",
            "Conv2D_with_same_padding-82            [-1, 288, 3, 3]           2,592\n",
            "      BatchNorm2d-83            [-1, 288, 3, 3]             576\n",
            "            Swish-84            [-1, 288, 3, 3]               0\n",
            "AdaptiveAvgPool2d-85            [-1, 288, 1, 1]               0\n",
            "           Conv2d-86             [-1, 12, 1, 1]           3,468\n",
            "            Swish-87             [-1, 12, 1, 1]               0\n",
            "           Conv2d-88            [-1, 288, 1, 1]           3,744\n",
            "SqueezeExcitationModule-89            [-1, 288, 3, 3]               0\n",
            "Conv2D_with_same_padding-90             [-1, 80, 3, 3]          23,040\n",
            "      BatchNorm2d-91             [-1, 80, 3, 3]             160\n",
            "           MBConv-92             [-1, 80, 3, 3]               0\n",
            "Conv2D_with_same_padding-93            [-1, 480, 3, 3]          38,400\n",
            "      BatchNorm2d-94            [-1, 480, 3, 3]             960\n",
            "            Swish-95            [-1, 480, 3, 3]               0\n",
            "Conv2D_with_same_padding-96            [-1, 480, 3, 3]           4,320\n",
            "      BatchNorm2d-97            [-1, 480, 3, 3]             960\n",
            "            Swish-98            [-1, 480, 3, 3]               0\n",
            "AdaptiveAvgPool2d-99            [-1, 480, 1, 1]               0\n",
            "          Conv2d-100             [-1, 20, 1, 1]           9,620\n",
            "           Swish-101             [-1, 20, 1, 1]               0\n",
            "          Conv2d-102            [-1, 480, 1, 1]          10,080\n",
            "SqueezeExcitationModule-103            [-1, 480, 3, 3]               0\n",
            "Conv2D_with_same_padding-104             [-1, 80, 3, 3]          38,400\n",
            "     BatchNorm2d-105             [-1, 80, 3, 3]             160\n",
            "        Identity-106             [-1, 80, 3, 3]               0\n",
            "          MBConv-107             [-1, 80, 3, 3]               0\n",
            "Conv2D_with_same_padding-108            [-1, 480, 3, 3]          38,400\n",
            "     BatchNorm2d-109            [-1, 480, 3, 3]             960\n",
            "           Swish-110            [-1, 480, 3, 3]               0\n",
            "Conv2D_with_same_padding-111            [-1, 480, 3, 3]           4,320\n",
            "     BatchNorm2d-112            [-1, 480, 3, 3]             960\n",
            "           Swish-113            [-1, 480, 3, 3]               0\n",
            "AdaptiveAvgPool2d-114            [-1, 480, 1, 1]               0\n",
            "          Conv2d-115             [-1, 20, 1, 1]           9,620\n",
            "           Swish-116             [-1, 20, 1, 1]               0\n",
            "          Conv2d-117            [-1, 480, 1, 1]          10,080\n",
            "SqueezeExcitationModule-118            [-1, 480, 3, 3]               0\n",
            "Conv2D_with_same_padding-119             [-1, 80, 3, 3]          38,400\n",
            "     BatchNorm2d-120             [-1, 80, 3, 3]             160\n",
            "        Identity-121             [-1, 80, 3, 3]               0\n",
            "          MBConv-122             [-1, 80, 3, 3]               0\n",
            "         MBBlock-123             [-1, 80, 3, 3]               0\n",
            "Conv2D_with_same_padding-124            [-1, 480, 3, 3]          38,400\n",
            "     BatchNorm2d-125            [-1, 480, 3, 3]             960\n",
            "           Swish-126            [-1, 480, 3, 3]               0\n",
            "Conv2D_with_same_padding-127            [-1, 480, 3, 3]          12,000\n",
            "     BatchNorm2d-128            [-1, 480, 3, 3]             960\n",
            "           Swish-129            [-1, 480, 3, 3]               0\n",
            "AdaptiveAvgPool2d-130            [-1, 480, 1, 1]               0\n",
            "          Conv2d-131             [-1, 20, 1, 1]           9,620\n",
            "           Swish-132             [-1, 20, 1, 1]               0\n",
            "          Conv2d-133            [-1, 480, 1, 1]          10,080\n",
            "SqueezeExcitationModule-134            [-1, 480, 3, 3]               0\n",
            "Conv2D_with_same_padding-135            [-1, 120, 3, 3]          57,600\n",
            "     BatchNorm2d-136            [-1, 120, 3, 3]             240\n",
            "          MBConv-137            [-1, 120, 3, 3]               0\n",
            "Conv2D_with_same_padding-138            [-1, 720, 3, 3]          86,400\n",
            "     BatchNorm2d-139            [-1, 720, 3, 3]           1,440\n",
            "           Swish-140            [-1, 720, 3, 3]               0\n",
            "Conv2D_with_same_padding-141            [-1, 720, 3, 3]          18,000\n",
            "     BatchNorm2d-142            [-1, 720, 3, 3]           1,440\n",
            "           Swish-143            [-1, 720, 3, 3]               0\n",
            "AdaptiveAvgPool2d-144            [-1, 720, 1, 1]               0\n",
            "          Conv2d-145             [-1, 30, 1, 1]          21,630\n",
            "           Swish-146             [-1, 30, 1, 1]               0\n",
            "          Conv2d-147            [-1, 720, 1, 1]          22,320\n",
            "SqueezeExcitationModule-148            [-1, 720, 3, 3]               0\n",
            "Conv2D_with_same_padding-149            [-1, 120, 3, 3]          86,400\n",
            "     BatchNorm2d-150            [-1, 120, 3, 3]             240\n",
            "        Identity-151            [-1, 120, 3, 3]               0\n",
            "          MBConv-152            [-1, 120, 3, 3]               0\n",
            "Conv2D_with_same_padding-153            [-1, 720, 3, 3]          86,400\n",
            "     BatchNorm2d-154            [-1, 720, 3, 3]           1,440\n",
            "           Swish-155            [-1, 720, 3, 3]               0\n",
            "Conv2D_with_same_padding-156            [-1, 720, 3, 3]          18,000\n",
            "     BatchNorm2d-157            [-1, 720, 3, 3]           1,440\n",
            "           Swish-158            [-1, 720, 3, 3]               0\n",
            "AdaptiveAvgPool2d-159            [-1, 720, 1, 1]               0\n",
            "          Conv2d-160             [-1, 30, 1, 1]          21,630\n",
            "           Swish-161             [-1, 30, 1, 1]               0\n",
            "          Conv2d-162            [-1, 720, 1, 1]          22,320\n",
            "SqueezeExcitationModule-163            [-1, 720, 3, 3]               0\n",
            "Conv2D_with_same_padding-164            [-1, 120, 3, 3]          86,400\n",
            "     BatchNorm2d-165            [-1, 120, 3, 3]             240\n",
            "        Identity-166            [-1, 120, 3, 3]               0\n",
            "          MBConv-167            [-1, 120, 3, 3]               0\n",
            "         MBBlock-168            [-1, 120, 3, 3]               0\n",
            "Conv2D_with_same_padding-169            [-1, 720, 3, 3]          86,400\n",
            "     BatchNorm2d-170            [-1, 720, 3, 3]           1,440\n",
            "           Swish-171            [-1, 720, 3, 3]               0\n",
            "Conv2D_with_same_padding-172            [-1, 720, 2, 2]          18,000\n",
            "     BatchNorm2d-173            [-1, 720, 2, 2]           1,440\n",
            "           Swish-174            [-1, 720, 2, 2]               0\n",
            "AdaptiveAvgPool2d-175            [-1, 720, 1, 1]               0\n",
            "          Conv2d-176             [-1, 30, 1, 1]          21,630\n",
            "           Swish-177             [-1, 30, 1, 1]               0\n",
            "          Conv2d-178            [-1, 720, 1, 1]          22,320\n",
            "SqueezeExcitationModule-179            [-1, 720, 2, 2]               0\n",
            "Conv2D_with_same_padding-180            [-1, 192, 2, 2]         138,240\n",
            "     BatchNorm2d-181            [-1, 192, 2, 2]             384\n",
            "          MBConv-182            [-1, 192, 2, 2]               0\n",
            "Conv2D_with_same_padding-183           [-1, 1152, 2, 2]         221,184\n",
            "     BatchNorm2d-184           [-1, 1152, 2, 2]           2,304\n",
            "           Swish-185           [-1, 1152, 2, 2]               0\n",
            "Conv2D_with_same_padding-186           [-1, 1152, 2, 2]          28,800\n",
            "     BatchNorm2d-187           [-1, 1152, 2, 2]           2,304\n",
            "           Swish-188           [-1, 1152, 2, 2]               0\n",
            "AdaptiveAvgPool2d-189           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-190             [-1, 48, 1, 1]          55,344\n",
            "           Swish-191             [-1, 48, 1, 1]               0\n",
            "          Conv2d-192           [-1, 1152, 1, 1]          56,448\n",
            "SqueezeExcitationModule-193           [-1, 1152, 2, 2]               0\n",
            "Conv2D_with_same_padding-194            [-1, 192, 2, 2]         221,184\n",
            "     BatchNorm2d-195            [-1, 192, 2, 2]             384\n",
            "        Identity-196            [-1, 192, 2, 2]               0\n",
            "          MBConv-197            [-1, 192, 2, 2]               0\n",
            "Conv2D_with_same_padding-198           [-1, 1152, 2, 2]         221,184\n",
            "     BatchNorm2d-199           [-1, 1152, 2, 2]           2,304\n",
            "           Swish-200           [-1, 1152, 2, 2]               0\n",
            "Conv2D_with_same_padding-201           [-1, 1152, 2, 2]          28,800\n",
            "     BatchNorm2d-202           [-1, 1152, 2, 2]           2,304\n",
            "           Swish-203           [-1, 1152, 2, 2]               0\n",
            "AdaptiveAvgPool2d-204           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-205             [-1, 48, 1, 1]          55,344\n",
            "           Swish-206             [-1, 48, 1, 1]               0\n",
            "          Conv2d-207           [-1, 1152, 1, 1]          56,448\n",
            "SqueezeExcitationModule-208           [-1, 1152, 2, 2]               0\n",
            "Conv2D_with_same_padding-209            [-1, 192, 2, 2]         221,184\n",
            "     BatchNorm2d-210            [-1, 192, 2, 2]             384\n",
            "        Identity-211            [-1, 192, 2, 2]               0\n",
            "          MBConv-212            [-1, 192, 2, 2]               0\n",
            "Conv2D_with_same_padding-213           [-1, 1152, 2, 2]         221,184\n",
            "     BatchNorm2d-214           [-1, 1152, 2, 2]           2,304\n",
            "           Swish-215           [-1, 1152, 2, 2]               0\n",
            "Conv2D_with_same_padding-216           [-1, 1152, 2, 2]          28,800\n",
            "     BatchNorm2d-217           [-1, 1152, 2, 2]           2,304\n",
            "           Swish-218           [-1, 1152, 2, 2]               0\n",
            "AdaptiveAvgPool2d-219           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-220             [-1, 48, 1, 1]          55,344\n",
            "           Swish-221             [-1, 48, 1, 1]               0\n",
            "          Conv2d-222           [-1, 1152, 1, 1]          56,448\n",
            "SqueezeExcitationModule-223           [-1, 1152, 2, 2]               0\n",
            "Conv2D_with_same_padding-224            [-1, 192, 2, 2]         221,184\n",
            "     BatchNorm2d-225            [-1, 192, 2, 2]             384\n",
            "        Identity-226            [-1, 192, 2, 2]               0\n",
            "          MBConv-227            [-1, 192, 2, 2]               0\n",
            "         MBBlock-228            [-1, 192, 2, 2]               0\n",
            "Conv2D_with_same_padding-229           [-1, 1152, 2, 2]         221,184\n",
            "     BatchNorm2d-230           [-1, 1152, 2, 2]           2,304\n",
            "           Swish-231           [-1, 1152, 2, 2]               0\n",
            "Conv2D_with_same_padding-232           [-1, 1152, 2, 2]          10,368\n",
            "     BatchNorm2d-233           [-1, 1152, 2, 2]           2,304\n",
            "           Swish-234           [-1, 1152, 2, 2]               0\n",
            "AdaptiveAvgPool2d-235           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-236             [-1, 48, 1, 1]          55,344\n",
            "           Swish-237             [-1, 48, 1, 1]               0\n",
            "          Conv2d-238           [-1, 1152, 1, 1]          56,448\n",
            "SqueezeExcitationModule-239           [-1, 1152, 2, 2]               0\n",
            "Conv2D_with_same_padding-240            [-1, 320, 2, 2]         368,640\n",
            "     BatchNorm2d-241            [-1, 320, 2, 2]             640\n",
            "          MBConv-242            [-1, 320, 2, 2]               0\n",
            "         MBBlock-243            [-1, 320, 2, 2]               0\n",
            "Conv2D_with_same_padding-244           [-1, 1280, 2, 2]         409,600\n",
            "     BatchNorm2d-245           [-1, 1280, 2, 2]           2,560\n",
            "           Swish-246           [-1, 1280, 2, 2]               0\n",
            "AdaptiveAvgPool2d-247           [-1, 1280, 1, 1]               0\n",
            "       Dropout2d-248           [-1, 1280, 1, 1]               0\n",
            "         Flatten-249                 [-1, 1280]               0\n",
            "          Linear-250                    [-1, 1]           1,281\n",
            "================================================================\n",
            "Total params: 4,145,101\n",
            "Trainable params: 4,145,101\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.02\n",
            "Forward/backward pass size (MB): 8.73\n",
            "Params size (MB): 15.81\n",
            "Estimated Total Size (MB): 24.56\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KheqE51B0QoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), './CactiNet.pb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVj8rLjr15y5",
        "colab_type": "text"
      },
      "source": [
        "##Training CactiNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNtQ_Gs-0uNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "# files.upload()\n",
        "#Upload the kaggle.json file here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G19ms8-k2Utv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB8uRr0Q2eGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4546ed81-f9d4-422b-d5b4-4f47f5612bf2"
      },
      "source": [
        "!kaggle competitions download -c aerial-cactus-identification"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/160k [00:00<?, ?B/s]\n",
            "100% 160k/160k [00:00<00:00, 60.5MB/s]\n",
            "Downloading test.zip to /content\n",
            "  0% 0.00/4.20M [00:00<?, ?B/s]\n",
            "100% 4.20M/4.20M [00:00<00:00, 69.5MB/s]\n",
            "Downloading train.zip to /content\n",
            " 47% 9.00M/19.2M [00:00<00:00, 52.7MB/s]\n",
            "100% 19.2M/19.2M [00:00<00:00, 76.2MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/667k [00:00<?, ?B/s]\n",
            "100% 667k/667k [00:00<00:00, 210MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUsYneuy2fCH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "797fb5ab-7d55-4fab-9a95-7de9a4890aa4"
      },
      "source": [
        "# !unzip train.zip\n",
        "# !unzip test.zip\n",
        "!ls"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CactiNet.pb  sample_data\t    test      train\t train.zip\n",
            "kaggle.json  sample_submission.csv  test.zip  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJF-7oDv2lH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = './train'\n",
        "test = './test'\n",
        "\n",
        "train_labels =  pd.read_csv('./train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eKC1H6Z2vJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, df, data_dir, transform):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.df.id[index]\n",
        "        label = self.df.has_cactus[index]\n",
        "\n",
        "        img_path = os.path.join(self.data_dir, img_name)\n",
        "        img = mpimg.imread(img_path)\n",
        "        img = self.transform(img)\n",
        "        return img, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egkZswSX2zGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transf = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor()])\n",
        "train_data = Data(df = train_labels, data_dir = train, transform = data_transf)\n",
        "train_loader = DataLoader(dataset = train_data, batch_size = 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uBO9VcJ24wI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDNH16xC3C2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_func = nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35R_0c6s3KVt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "9a76abc0-6146-43c8-e5ce-72b7429fb758"
      },
      "source": [
        "%%time\n",
        "loss_log = []\n",
        "val_loss_log = []\n",
        "n_epochs = 10\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, n_epochs - 1))\n",
        "    print('-' * 50)\n",
        "\n",
        "    model.train()\n",
        "    for step, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "        target = target.float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        m = nn.Sigmoid()\n",
        "        loss = loss_func(m(output), target)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            loss_log.append(loss.item())      \n",
        "\n",
        "    print('Epoch: {} - Loss: {}'.format(epoch+1, loss.item()))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/9\n",
            "--------------------------------------------------\n",
            "Epoch: 1 - Loss: 0.23227491974830627\n",
            "Epoch 1/9\n",
            "--------------------------------------------------\n",
            "Epoch: 2 - Loss: 0.043363459408283234\n",
            "Epoch 2/9\n",
            "--------------------------------------------------\n",
            "Epoch: 3 - Loss: 0.02042786218225956\n",
            "Epoch 3/9\n",
            "--------------------------------------------------\n",
            "Epoch: 4 - Loss: 0.009691665880382061\n",
            "Epoch 4/9\n",
            "--------------------------------------------------\n",
            "Epoch: 5 - Loss: 0.0021468650083988905\n",
            "Epoch 5/9\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-ed2854022663>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss_log = []\\nval_loss_log = []\\nn_epochs = 10\\n\\nfor epoch in range(n_epochs):\\n    print('Epoch {}/{}'.format(epoch, n_epochs - 1))\\n    print('-' * 50)\\n\\n    model.train()\\n    for step, (data, target) in enumerate(train_loader):\\n        data, target = data.cuda(), target.cuda()\\n        target = target.float()\\n\\n        optimizer.zero_grad()\\n        output = model(data)\\n\\n        m = nn.Sigmoid()\\n        loss = loss_func(m(output), target)\\n        loss.backward()\\n\\n        optimizer.step()\\n\\n        if step % 10 == 0:\\n            loss_log.append(loss.item())      \\n\\n    print('Epoch: {} - Loss: {}'.format(epoch+1, loss.item()))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-9968730666f8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-ba98a5d40e89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-ba98a5d40e89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth_wise_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use cumulative moving average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0mexponential_average_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnSZgKtB6DD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "f735472f-74af-4063-ceee-641c269f8002"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.title('Training loss')\n",
        "plt.plot(loss_log)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd4c20c6080>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAHiCAYAAADMP0mlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQqHwgf8POtF4/87okEkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK13CAiy6GRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit = pd.read_csv('./sample_submission.csv')\n",
        "test_data = Data(df = submit, data_dir = test, transform = data_transf) \n",
        "test_loader = DataLoader(dataset = test_data, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wU4aesF6R-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9db53dfd-36fe-4fe3-b9cd-0817c0691a12"
      },
      "source": [
        "%%time\n",
        "predictions = []\n",
        "model.eval()\n",
        "for i, (data, _) in enumerate(test_loader):\n",
        "    data = data.cuda()\n",
        "    output = model(data)\n",
        "\n",
        "    pred = torch.sigmoid(output)\n",
        "    predictions.append(pred.item())"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 48.9 s, sys: 124 ms, total: 49 s\n",
            "Wall time: 49 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw9xO_Lo6Vgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit['has_cactus'] = predictions\n",
        "submit.to_csv('submission1.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e9ASW1n89Fn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('./submission1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}